{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce24ede4-fe44-4cda-ac46-aa2907306d42",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64baf24b-df56-42b1-8e63-b1f45a5dd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#install': Expected package name at the start of dependency specifier\n",
      "    #install\n",
      "    ^\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk #install library \n",
    "import nltk #import library \n",
    "nltk.download('punkt') #download tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89e268b-5e66-4da2-a07b-c19f44b59bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c92568c-0f05-4521-b8ad-4c4980c479c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"The University of Faisalabad is a private institute. imparting high quality higher education at undergraduate. graduate and postgraduate level.\"            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e92177-1a0c-497e-bbfa-c3546a0ec618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60908d73-eba2-4dc6-ba28-06467a3cb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence\n",
    "words = word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d1dc56-b354-4580-99bf-2f1aa586a778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming result:\n",
      "['the', 'univers', 'of', 'faisalabad', 'is', 'a', 'privat', 'institut', '.', 'impart', 'high', 'qualiti', 'higher', 'educ', 'at', 'undergradu', '.', 'graduat', 'and', 'postgradu', 'level', '.']\n"
     ]
    }
   ],
   "source": [
    "# Apply stemming\n",
    "stems = [ps.stem(w) for w in words]\n",
    "print(\"Stemming result:\")\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47921ff2-5d18-4577-a8ae-d53ed59f6901",
   "metadata": {},
   "source": [
    "**Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72eaf8e-7b87-475e-ba6e-0e757f5e7d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719b8d93-d39f-4491-936f-69f5a81c9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b402b57c-9f14-4cfb-b1ae-cfac681366bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization result:\n",
      "['The', 'University', 'of', 'Faisalabad', 'is', 'a', 'private', 'institute', '.', 'imparting', 'high', 'quality', 'higher', 'education', 'at', 'undergraduate', '.', 'graduate', 'and', 'postgraduate', 'level', '.']\n"
     ]
    }
   ],
   "source": [
    "# Apply lemmatization\n",
    "lemmas = [lemmatizer.lemmatize(w) for w in words]\n",
    "print(\"Lemmatization result:\")\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27495f9-57c8-4f44-a181-87371d47ec5e",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423879cb-8711-46cf-af6d-25e74dcaebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize #import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0144e1-8250-4d2c-b4af-54e66dc1ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3ffefd-73a0-465c-85b9-529bdafdc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f5da6c-8537-43cf-8bb8-93146a1e014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a0f781-484d-4394-a622-797a6f90d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'University', 'of', 'Faisalabad', 'is', 'a', 'private', 'institute', '.', 'imparting', 'high', 'quality', 'higher', 'education', 'at', 'undergraduate', '.', 'graduate', 'and', 'postgraduate', 'level', '.']\n"
     ]
    }
   ],
   "source": [
    "print (word_tokenize(x)) #split text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ac27a8b-0375-4ce3-90d9-123ba53e0aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The University of Faisalabad is a private institute.', 'imparting high quality higher education at undergraduate.', 'graduate and postgraduate level.']\n"
     ]
    }
   ],
   "source": [
    "print (sent_tokenize(x)) #split text into sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d0217-578d-4e09-bd5c-dd35ca6bffeb",
   "metadata": {},
   "source": [
    "**POS Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b4c838-5ec9-4bd2-8fc4-13f9e46f0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8fb8e5a-785a-4b47-bee6-2f5e9f0142dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e67349b8-a5c3-4593-9c27-632ee3cfcc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e740ea-0a62-45de-b55b-5501ecda0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f8b921c-bcdf-4471-a1f4-48d01b60add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pos_tag(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef87ecd-51d1-4a13-a8a6-9cfdd01d888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Faisalabad', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('private', 'JJ'),\n",
       " ('institute', 'NN'),\n",
       " ('.', '.'),\n",
       " ('imparting', 'VBG'),\n",
       " ('high', 'JJ'),\n",
       " ('quality', 'NN'),\n",
       " ('higher', 'JJR'),\n",
       " ('education', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('undergraduate', 'NN'),\n",
       " ('.', '.'),\n",
       " ('graduate', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('postgraduate', 'JJ'),\n",
       " ('level', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893f141-a3cb-4fb7-afaf-fe81130636c3",
   "metadata": {},
   "source": [
    "**Lowercasing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9655273-919a-474b-802b-2aaeed5c5257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the university of faisalabad is a private institute. imparting high quality higher education at undergraduate. graduate and postgraduate level.\n"
     ]
    }
   ],
   "source": [
    "text = x.lower() #remove uppercase\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0d251-0e0a-44ff-b189-9cf8f23e3564",
   "metadata": {},
   "source": [
    "**Remove special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a6bf99d-fcd2-40c3-9d0c-1c79aa0b26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fabde550-7f9c-41da-9825-62cfec44eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'university', 'of', 'faisalabad', 'is', 'a', 'private', 'institute', 'imparting', 'high', 'quality', 'higher', 'education', 'at', 'undergraduate', 'graduate', 'and', 'postgraduate', 'level']\n"
     ]
    }
   ],
   "source": [
    "text = text.translate(str.maketrans('', '', string.punctuation)) #remove punctuation/special characters\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d6746-f808-4868-ba20-c755ffd3fbce",
   "metadata": {},
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1905eb66-4725-466f-9e5e-c810a333be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d015dc34-3d64-4770-b92f-bc65284ed9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0644b903-fc4c-4114-9885-2cf35a2455c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['university', 'faisalabad', 'private', 'institute', 'imparting', 'high', 'quality', 'higher', 'education', 'undergraduate', 'graduate', 'postgraduate', 'level']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb9607-7c40-4b1c-9f91-563986c0a2c0",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e66dea60-f553-465e-a6e4-9bad50f5c153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'faisalabad', 'graduate', 'high', 'higher', 'imparting', 'institute', 'level', 'postgraduate', 'private', 'quality', 'undergraduate', 'university']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = sorted(set(filtered_tokens))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d3e9e-de6b-419f-8d08-4f1121f9d0df",
   "metadata": {},
   "source": [
    "**BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc66ccbe-82dc-44af-b1f7-c9d0892d8a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'university': 1, 'faisalabad': 1, 'private': 1, 'institute': 1, 'imparting': 1, 'high': 1, 'quality': 1, 'higher': 1, 'education': 1, 'undergraduate': 1, 'graduate': 1, 'postgraduate': 1, 'level': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bow = Counter(filtered_tokens)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a0e7d9b-473f-4973-a1ec-cee7ee980d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = [1 if word in filtered_tokens else 0 for word in vocabulary]\n",
    "print(\"x=\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690781fc-b3fc-424c-9f96-4fa10348d0ec",
   "metadata": {},
   "source": [
    "**Generate volcabulary And BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb2e7de1-3299-447c-a99a-0f02837f91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given corpus\n",
    "corpus = [\n",
    "    \"I am loving the NLP class, but sometimes it feels confusing!!!\",\n",
    "    \"NLP is a fascinating field — it deals with text, speech, and language understanding.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f5a3b47-c764-4d84-afbf-a515af5d5187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase:\n",
      "- i am loving the nlp class, but sometimes it feels confusing!!!\n",
      "- nlp is a fascinating field — it deals with text, speech, and language understanding.\n"
     ]
    }
   ],
   "source": [
    "#Lowercase \n",
    "lowered = [sent.lower() for sent in corpus]\n",
    "print(\"Lowercase:\")\n",
    "for s in lowered:\n",
    "    print(\"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b70803c7-bf28-4a06-a0b6-94cece253eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- i am loving the nlp class but sometimes it feels confusing\n",
      "- nlp is a fascinating field  it deals with text speech and language understanding\n"
     ]
    }
   ],
   "source": [
    "#Remove special characters \n",
    "cleaned = [re.sub(r'[^a-z0-9\\s]', '', s) for s in lowered]\n",
    "for s in cleaned:\n",
    "    print(\"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1009507-02d3-4cb5-abac-a1c645d49787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 tokens: ['i', 'am', 'loving', 'the', 'nlp', 'class', 'but', 'sometimes', 'it', 'feels', 'confusing']\n",
      "Sentence 2 tokens: ['nlp', 'is', 'a', 'fascinating', 'field', 'it', 'deals', 'with', 'text', 'speech', 'and', 'language', 'understanding']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize sentences into words\n",
    "tokenized = [word_tokenize(s) for s in cleaned]\n",
    "for i, toks in enumerate(tokenized, 1):\n",
    "    print(f\"Sentence {i} tokens:\", toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7168c8c7-f5bf-4a40-b62b-11010e6fc3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 filtered tokens: ['loving', 'nlp', 'class', 'sometimes', 'feels', 'confusing']\n",
      "Sentence 2 filtered tokens: ['nlp', 'fascinating', 'field', 'deals', 'text', 'speech', 'language', 'understanding']\n"
     ]
    }
   ],
   "source": [
    "#Remove stopwords (use NLTK's stopword list)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [\n",
    "    [tok for tok in toks if tok not in stop_words]\n",
    "    for toks in tokenized]\n",
    "for i, toks in enumerate(filtered_tokens, 1):\n",
    "    print(f\"Sentence {i} filtered tokens:\", toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869f1fb-abaa-4dbf-8a96-fdf6dfda3d45",
   "metadata": {},
   "source": [
    "**Create Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7970b954-9331-4397-8e61-10e880b75589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'confusing', 'deals', 'fascinating', 'feels', 'field', 'language', 'loving', 'nlp', 'sometimes', 'speech', 'text', 'understanding']\n"
     ]
    }
   ],
   "source": [
    "#vocabulary\n",
    "all_tokens = [tok for sent in filtered_tokens for tok in sent]\n",
    "vocabulary = sorted(set(all_tokens))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fdc69d-9bee-4a65-aed4-ea566ae3b1c1",
   "metadata": {},
   "source": [
    "**Generate BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70c39ead-bf28-49a2-980f-887d30bbe853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 BoW counts: [1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "Sentence 2 BoW counts: [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#Bag Of Words \n",
    "bow_counts = []\n",
    "for sent in filtered_tokens:\n",
    "    c = Counter(sent)\n",
    "    vector = [c[word] for word in vocabulary] # Build vector in vocabulary order (counts)\n",
    "    bow_counts.append(vector)\n",
    "for i, vec in enumerate(bow_counts, 1):\n",
    "    print(f\"Sentence {i} BoW counts:\", vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58db6ac-76a0-4a89-a0c8-fb63386dbfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
